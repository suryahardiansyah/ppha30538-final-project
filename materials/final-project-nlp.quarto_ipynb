{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Final Project - NLP Chicago Carjackings Shiny Dashboard\"\n",
        "author: \"Surya Hardiansyah and Astari Raihanah\"\n",
        "date: today\n",
        "format: \n",
        "  pdf:\n",
        "    include-in-header: \n",
        "       text: |\n",
        "         \\usepackage{fvextra}\n",
        "         \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n",
        "include-before-body:\n",
        "  text: |\n",
        "    \\RecustomVerbatimEnvironment{verbatim}{Verbatim}{\n",
        "      showspaces = false,\n",
        "      showtabs = false,\n",
        "      breaksymbolleft={},\n",
        "      breaklines\n",
        "    }\n",
        "---"
      ],
      "id": "c538f24a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "import spacy\n",
        "import time  # To avoid hitting rate limits\n",
        "\n",
        "# Load spaCy with TextBlob for Sentiment Analysis\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"spacytextblob\")\n",
        "\n",
        "# Function to fetch paginated results from SerpAPI\n",
        "def fetch_serpapi_results(query, api_key, num_results=100, start=0):\n",
        "    url = \"https://serpapi.com/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"hl\": \"en\",  # Language: English\n",
        "        \"gl\": \"us\",  # Country: US\n",
        "        \"api_key\": api_key,\n",
        "        \"num\": num_results,  # Max number of results per page\n",
        "        \"start\": start,  # Offset for pagination\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"organic_results\", [])\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, Message: {response.text}\")\n",
        "        return []\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    doc = nlp(text)\n",
        "    return doc._.blob.polarity, doc._.blob.subjectivity\n",
        "\n",
        "# SerpAPI key and expanded queries\n",
        "api_key = \"a294a642b519834b1905e86841770361e944c1b48eb3c597bc2f958893f31a4b\"\n",
        "queries = [\n",
        "    \"Chicago car insurance policy\",\n",
        "    \"auto insurance Chicago\",\n",
        "    \"carjacking auto insurance Chicago\",\n",
        "    \"auto insurance Chicago car theft\",\n",
        "    \"Chicago carjacking\",\n",
        "    \"Chicago car theft\"\n",
        "]\n",
        "\n",
        "# Collect results\n",
        "data = []\n",
        "for query in queries:\n",
        "    total_observations = 0\n",
        "    start = 0  # Start pagination from 0\n",
        "    while total_observations < 500:  # Target total of 500 results\n",
        "        results = fetch_serpapi_results(query, api_key, num_results=100, start=start)\n",
        "        if not results:\n",
        "            break  # Stop if no more results\n",
        "        for result in results:\n",
        "            title = result.get(\"title\", \"\")\n",
        "            link = result.get(\"link\", \"\")\n",
        "            snippet = result.get(\"snippet\", \"\")\n",
        "            date = result.get(\"date\", \"\")  # Published date if available\n",
        "            if snippet:  # Ensure snippet exists\n",
        "                polarity, subjectivity = analyze_sentiment(snippet)\n",
        "                data.append({\n",
        "                    \"query\": query,\n",
        "                    \"title\": title,\n",
        "                    \"link\": link,\n",
        "                    \"date_published\": date,\n",
        "                    \"snippet\": snippet,\n",
        "                    \"polarity\": polarity,\n",
        "                    \"subjectivity\": subjectivity\n",
        "                })\n",
        "        total_observations += len(results)\n",
        "        start += 100  # Move to the next page\n",
        "        time.sleep(2)  # Avoid hitting rate limits\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save results to CSV\n",
        "df.to_csv(\"serpapi_expanded_results_2.csv\", index=False)\n",
        "\n",
        "print(f\"Total results collected: {len(df)}\")"
      ],
      "id": "78374f77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import altair as alt\n",
        "\n",
        "# Load the data from the CSV file into a Pandas DataFrame\n",
        "data = pd.read_csv(\"serpapi_expanded_results_2.csv\")\n",
        "\n",
        "# Ensure Altair can render without row limits\n",
        "alt.data_transformers.disable_max_rows()\n",
        "\n",
        "# Average Polarity by Query \n",
        "avg_polarity_chart = (\n",
        "    alt.Chart(data)\n",
        "    .mark_bar(color=\"steelblue\")\n",
        "    .encode(\n",
        "        x=alt.X(\"query:N\", title=\"Query\", sort=\"-y\"),\n",
        "        y=alt.Y(\"mean(polarity):Q\", title=\"Average Polarity\"),\n",
        "        tooltip=[\"query\", \"mean(polarity):Q\"]\n",
        "    )\n",
        "    .properties(title=\"Average Sentiment Polarity by Query\", width=600, height=400)\n",
        ")\n",
        "\n",
        "# Add text labels for the bars\n",
        "text = avg_polarity_chart.mark_text(\n",
        "    align='center',\n",
        "    baseline='middle',\n",
        "    dy=-10  # Adjust position of the text above the bars\n",
        ").encode(\n",
        "    text=alt.Text(\"mean(polarity):Q\", format=\".2f\")\n",
        ")\n",
        "\n",
        "# Combine bar chart with text labels\n",
        "avg_polarity_with_labels = avg_polarity_chart + text\n",
        "\n",
        "# Average Subjectivity by Query\n",
        "avg_subjectivity_chart = (\n",
        "    alt.Chart(data)\n",
        "    .mark_bar(color=\"orange\") \n",
        "    .encode(\n",
        "        x=alt.X(\"query:N\", title=\"Query\", sort=\"-y\"),\n",
        "        y=alt.Y(\"mean(subjectivity):Q\", title=\"Average Subjectivity\"),\n",
        "        tooltip=[\"query\", \"mean(subjectivity):Q\"]\n",
        "    )\n",
        "    .properties(title=\"Average Subjectivity by Query\", width=600, height=400)\n",
        ")\n",
        "\n",
        "# Add text labels for the bars\n",
        "text_subjectivity = avg_subjectivity_chart.mark_text(\n",
        "    align='center',\n",
        "    baseline='middle',\n",
        "    dy=-10  # Adjust position of the text above the bars\n",
        ").encode(\n",
        "    text=alt.Text(\"mean(subjectivity):Q\", format=\".2f\")\n",
        ")\n",
        "\n",
        "# Combine bar chart with text labels\n",
        "avg_subjectivity_with_labels = avg_subjectivity_chart + text_subjectivity\n",
        "\n",
        "# Display the charts\n",
        "avg_polarity_with_labels | avg_subjectivity_with_labels"
      ],
      "id": "fd1bd81d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\raiha\\AppData\\Local\\Programs\\Python\\Python312\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}